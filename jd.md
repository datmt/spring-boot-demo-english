> Company: Hangzhou Tuya Information Technology Co., Ltd. is a global cloud development platform, AI+IoT developer platform, connecting the intelligent needs of consumers, manufacturing brands, OEMs and chain retailers, providing developers with one-stop artificial intelligence Internet of Things PaaS-level solutions. It also covers the development of hardware development tools, global cloud, and smart business platform, providing comprehensive ecological empowerment from technology to marketing channels, and creating a world-leading IoT OS.
>
> Team: Cloud Development/Data Platform
>
> Base: Hangzhou

The group recruits people, HC huge number of ~~ interested friends, resume sent over,:kissing_heart:

> WeChat: syk941020
>
> E-mail: 237497819@qq.com
>
> Remarks: internal push + post

---

# Job list

* [Job List](#岗位列表)
  * [Advanced Java Development - Big Data Direction] (#高级java开发 - Big Data Direction)
     * [[Job Description](#职位描述)
     * [[Job Requirements](#职位要求)
  * [Senior Java Big Data Platform Development Engineer](#高级java大数据平台开发工程师)
     * [[Job Description](#职位描述-1)
     * [[Job Requirements](#职位要求-1)
  * [Big Data Development Engineer (flink)](#大数据开发工程师flink方向)
     * [[Job Responsibilities](#岗位职责)
     * [[Job Requirements](#任职要求)
  * [Senior Data Warehouse Development Engineer] (#高级数据仓库开发工程师)
     * [[Job Description](#岗位描述)
     * [[Skill Requirements](#技能要求)
  * [bi analyst] (#bi分析师)
     * [[Job Responsibilities](#岗位职责-1)
     * [[Job Requirements](#任职要求-1)
  * [Big Data Platform Architect](#大数据平台架构师)
     * [[Job Description](#职位描述-2)
     * [[Job Requirements](#职位要求-2)

## Advanced Java Development - Big Data Direction

### 【Job Description】

1. Proficient in Java open source framework, Java development language
3. Excellent learning ability of new technologies, master mybatis, Spring MVC and other technologies
3. Participate in the research and development and direction rehearsal of the company's big data products and core architecture;
4. Broaden your mind and enjoy learning to improve your ability and efficiency;

### 【Job Requirements】

1. Proficient in Java language, in-depth understanding of open source products in related technical fields;
2. I hope you have more than 3 years of Java related experience;
3. Familiar with common system tools under Linux, can use tools to troubleshoot CPU, memory, IO and other system problems;
4. Engaged in large-scale Web application development, familiar with code refactoring, performance optimization, system security and high availability;
5. Familiar with non-relational databases such as Redis, Hbase, etc.
6. Have experience in the development of hbase, elasticsearch, flink, tidb, clickhouse, and have an in-depth researcher for these 5 is preferred.
7. Experience in data application product development is preferred.

## Senior Java Big Data Platform Development Engineer

### 【Job Description】

1. Responsible for the design and development of big data platform
2. Responsible for product requirements analysis, architecture design, and development and implementation of big data applications
3. Responsible for the development and maintenance of service interfaces for data products

### 【Job Requirements】

1. Bachelor degree or above, 2 years or above in big data related technical background
2. Proficient in Java code writing, good code writing literacy, good data structure algorithm skills.
3. Familiar with spring boot, mybatis, dubbo and other development frameworks, familiar with the front and back end separation development process
4. Experience in big data platform development, including but not limited to offline development platform, data quality center, metadata management, data asset management, real-time streaming platform, visual reports, etc
5. Familiar with open source big data platforms such as HBase, ES, Kylin, tidb, clickhouse and other related technologies
6. Those who have used flink as a real-time computing platform success case and those who have used the hera system to do offline tasks are preferred.

## Big Data Development Engineer (flink direction)

### 【Job Responsibilities】

1. Responsible for real-time collection, calculation, storage and service of business data and user behavior logs, and provide direct data decision-making for business teams;
2. Responsible for the construction of the department's real-time computing architecture and the development and improvement of the real-time computing platform.
3. Responsible for the exploration of relevant technical solutions for real-time analysis
4. Responsible for the construction of real-time data warehouse and improve the real-time computing solution

### 【Job Requirements】

1. In-depth understanding of offline computing and related development, master the real-time computing technology system including data collection, calculation engine flink, etc., have a deep understanding of the transactions, fault tolerance and reliability involved in real-time computing and have practical project experience;
2. Familiar with the hadoop ecosystem including hdfs/mapreduce/hive/hbase, familiar with real-time open source tools such as kafka and project experience;
3. Familiar with mysql and other relational databases, familiar with redis memory database, familiar with Linux system;
4. Master Java or Scala languages such as concurrent programming and JVM, etc., and pursue high standards of engineering quality;
5. Have experience in flink real-time computing development, familiar with the relevant technologies of olap.
6. Have good communication skills and self-driving motivation, have excellent planning, execution, a strong sense of responsibility, and excellent learning ability, have enthusiasm for technology, and are willing to constantly try new technologies and business challenges.

## Senior Data Warehouse Development Engineer

### 【Job Description】

1. Responsible for data warehouse architecture design, modeling and ETL development;
2. Participate in data governance to improve data ease of use and data quality;
3. Understand and reasonably abstract business requirements, exert data value, and work closely with business and BI teams.

### 【Skill Requirements】

1. Have experience in data warehouse requirements research and requirements analysis, design data warehouse models according to business needs, and manage data warehouse data models to ensure data quality.
2. Proficient in sql development, rich experience in spark sql performance tuning is preferred;
3. Proficient in data warehouse implementation methodology, in-depth understanding of data warehouse system, and support actual business scenarios;
4. Familiar with the relevant aspects of data governance, relevant development experience or practical application scenarios;
5. Have strong coding ability, familiar with many in sql, python, hive, spark, kafka, storm;
6. Sensitive to data, careful and meticulous, good at finding doubts from data;
7. Good at communication, with excellent technical and business combination ability.

## bi analyst

### 【Job Responsibilities】

1. Provide data support for the company's technology, operation, products, business strategies, etc.;
2. Maintain and improve the data reporting system, timely and accurately monitor the operation status, and provide professional analysis reports;
3. Discover problems and opportunities in business and process through data, put forward corresponding optimization suggestions for business departments from the perspective of data, and cooperate with multiple parties to achieve process improvement and promote the achievement of relevant business objectives;
4. Precipitate analysis ideas and frameworks, refine data product requirements, collaborate with relevant teams and promote the landing of data products;

### 【Job Requirements】

1. Bachelor degree or above, more than 2 years working experience, Internet data analysis experience is preferred;
2. Solid data analysis, data statistics theory, good at summarizing abstract problems;
3. Proficient in Excel, proficient in SQL queries and other operations, proficient in using at least one data analysis tool (R, Python, SPSS, etc.) is preferred;
4. Have good learning ability, communication and presentation ability and teamwork ability.

## Big Data Platform Architect

### 【Job Description】

1. Responsible for the development and construction of Tuya big data platform, establish data ecological services, and solve the challenges faced by massive data
2. Participate in the design and engine development of various basic system architectures of the big data platform, cluster optimization, and technical difficulties
3. Construction of cluster data security related system, various storage, query scheme construction
4. Assist in the management, optimization and maintenance of Hadoop, Spark, flink and other clusters to ensure that the cluster scale is continuous and stable;
5. Responsible for the design and development of platforms such as automation, offline and real-time computing, ad-hoc computing, data quality, and data security of big data products;
6. Investigate and grasp the current latest technology, introduce the advanced technology into their own platform, improve products, enhance competitiveness

### 【Job Requirements】

1. Bachelor degree or above, more than 5 years working experience, more than 3 years working experience in the field of big data, familiar with java, spark
2. Familiar with open source big data platforms such as HBase, ES, Kylin, Druid, etc., with practical experience in the actual construction of reporting platforms, multi-dimensional analysis tools, etl platforms, scheduling platforms, and real-time platforms.
3. Have experience in the architecture and development of practically successful complex system projects based on the relevant systems described above
4. Love open source technology, familiar with one or more big data ecological technologies (Kafka, Hive, Hbase, Spark, Storm, Hadoop, Flink, kudu, clickhouse, tidb, etc.), familiar with the source code is preferred
5. Active contributors in related open source fields or relevant experience in large Internet companies are preferred.
6. Those who have used flink as a real-time computing platform success case and those who have used the hera system to do offline tasks are preferred.
